import flwr as fl
import torch
import torch.nn as nn
from typing import Dict
from sklearn.preprocessing import StandardScaler
from torch.utils.data import Dataset
import logging


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåœ¨æ¯ä¸€è½®è®­ç»ƒå¼€å§‹æ—¶ä¼ é€’è½®æ¬¡ä¿¡æ¯
def get_fit_config(server_round: int) -> Dict[str, int]:
    return {"current_round": server_round}  # å°†è½®æ¬¡ä¿¡æ¯ä¼ é€’ç»™å®¢æˆ·ç«¯

# è¯„ä¼°å‡½æ•°
def start(file_name):
    #è®¾ç½®ğŸ“”
    logging.basicConfig(
        filename=f'./data/log/{file_name}.log',  # æ–°å¢ï¼šè¾“å‡ºæ—¥å¿—åˆ°æ–‡ä»¶
        level=logging.INFO,  # æ–°å¢ï¼šæ—¥å¿—çº§åˆ«
        format='%(asctime)s - %(levelname)s - %(message)s',  # æ–°å¢ï¼šæ—¥å¿—æ ¼å¼
    )

    # å®šä¹‰è”é‚¦ç­–ç•¥
    strategy = fl.server.strategy.FedAvg(
        fraction_fit=1.0,
        fraction_evaluate=1, 
        min_fit_clients=1,
        min_available_clients=1,
        min_evaluate_clients=1,
        on_fit_config_fn=get_fit_config,  # è®¾ç½®å›è°ƒå‡½æ•°
    )
    
    # å¯åŠ¨æœåŠ¡å™¨
    fl.server.start_server(
        server_address="0.0.0.0:10001",
        config=fl.server.ServerConfig(num_rounds=10),
        strategy=strategy,
    )

if __name__ == "__main__":
    # å¼€å¯æ–°è¿›ç¨‹å¼€å¯æœåŠ¡
    import multiprocessing
    p = multiprocessing.Process(target=start)
    p.daemon = False 
    p.start()
    print("Server started")
